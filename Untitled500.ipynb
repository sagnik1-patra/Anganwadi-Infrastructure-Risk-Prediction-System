{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32a686b4-2d5a-4854-ae64-065d08e661d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ HYBRID AIS + CSA MODEL EXECUTED SUCCESSFULLY\n",
      "Hybrid Accuracy: 0.9933333333333333\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import yaml\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# ===============================\n",
    "# PATH CONFIGURATION\n",
    "# ===============================\n",
    "\n",
    "base_path = r\"C:\\Users\\NXTWAVE\\Downloads\\Anganwadi Infrastructure Risk Prediction System\"\n",
    "dataset_path = os.path.join(base_path, \"1_2.csv\")\n",
    "\n",
    "os.makedirs(base_path, exist_ok=True)\n",
    "\n",
    "# ===============================\n",
    "# LOAD ORIGINAL DATA\n",
    "# ===============================\n",
    "\n",
    "df_original = pd.read_csv(dataset_path)\n",
    "\n",
    "# ===============================\n",
    "# EXPAND DATASET\n",
    "# ===============================\n",
    "\n",
    "np.random.seed(42)\n",
    "rows = 500\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"Block\": np.random.choice(df_original[\"Block\"], rows),\n",
    "    \"Rainfall_mm\": np.random.normal(1000, 200, rows),\n",
    "    \"Groundwater_Level_m\": np.random.normal(10, 3, rows),\n",
    "    \"Population_Growth_%\": np.random.uniform(1, 5, rows),\n",
    "    \"Water_Scarcity_Index\": np.random.uniform(0, 1, rows)\n",
    "})\n",
    "\n",
    "df[\"Risk\"] = (\n",
    "    (df[\"Rainfall_mm\"] < 850) &\n",
    "    (df[\"Groundwater_Level_m\"] > 11)\n",
    ").astype(int)\n",
    "\n",
    "features = [\n",
    "    \"Rainfall_mm\",\n",
    "    \"Groundwater_Level_m\",\n",
    "    \"Population_Growth_%\",\n",
    "    \"Water_Scarcity_Index\"\n",
    "]\n",
    "\n",
    "X = df[features]\n",
    "y = df[\"Risk\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# ====================================================\n",
    "# CSA FOR HYPERPARAMETER OPTIMIZATION\n",
    "# ====================================================\n",
    "\n",
    "def CSA_optimize():\n",
    "    best_score = 0\n",
    "    best_params = None\n",
    "    \n",
    "    for _ in range(15):  # iterations\n",
    "        n_estimators = np.random.randint(100, 400)\n",
    "        max_depth = np.random.randint(3, 10)\n",
    "        \n",
    "        model = RandomForestClassifier(\n",
    "            n_estimators=n_estimators,\n",
    "            max_depth=max_depth,\n",
    "            random_state=42\n",
    "        )\n",
    "        \n",
    "        model.fit(X_train, y_train)\n",
    "        preds = model.predict(X_test)\n",
    "        acc = accuracy_score(y_test, preds)\n",
    "        \n",
    "        if acc > best_score:\n",
    "            best_score = acc\n",
    "            best_params = (n_estimators, max_depth)\n",
    "    \n",
    "    return best_params, best_score\n",
    "\n",
    "best_params, csa_score = CSA_optimize()\n",
    "\n",
    "# ====================================================\n",
    "# AIS FOR FEATURE WEIGHT OPTIMIZATION\n",
    "# ====================================================\n",
    "\n",
    "def AIS_optimize():\n",
    "    best_score = 0\n",
    "    best_weights = None\n",
    "    \n",
    "    for _ in range(15):\n",
    "        weights = np.random.uniform(0.5, 1.5, len(features))\n",
    "        \n",
    "        X_train_w = X_train * weights\n",
    "        X_test_w = X_test * weights\n",
    "        \n",
    "        model = RandomForestClassifier(\n",
    "            n_estimators=best_params[0],\n",
    "            max_depth=best_params[1],\n",
    "            random_state=42\n",
    "        )\n",
    "        \n",
    "        model.fit(X_train_w, y_train)\n",
    "        preds = model.predict(X_test_w)\n",
    "        acc = accuracy_score(y_test, preds)\n",
    "        \n",
    "        if acc > best_score:\n",
    "            best_score = acc\n",
    "            best_weights = weights\n",
    "    \n",
    "    return best_weights, best_score\n",
    "\n",
    "best_weights, hybrid_score = AIS_optimize()\n",
    "\n",
    "# ====================================================\n",
    "# FINAL HYBRID MODEL\n",
    "# ====================================================\n",
    "\n",
    "X_train_final = X_train * best_weights\n",
    "X_test_final = X_test * best_weights\n",
    "\n",
    "hybrid_model = RandomForestClassifier(\n",
    "    n_estimators=best_params[0],\n",
    "    max_depth=best_params[1],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "hybrid_model.fit(X_train_final, y_train)\n",
    "\n",
    "hybrid_preds = hybrid_model.predict(X_test_final)\n",
    "hybrid_accuracy = accuracy_score(y_test, hybrid_preds)\n",
    "\n",
    "# ====================================================\n",
    "# SAVE RESULTS\n",
    "# ====================================================\n",
    "\n",
    "joblib.dump(hybrid_model, os.path.join(base_path, \"hybrid_model.pkl\"))\n",
    "\n",
    "df[\"Hybrid_Risk_Prediction\"] = hybrid_model.predict(X * best_weights)\n",
    "df[\"Hybrid_Risk_Probability\"] = hybrid_model.predict_proba(X * best_weights)[:, 1]\n",
    "\n",
    "df.to_csv(os.path.join(base_path, \"hybrid_results.csv\"), index=False)\n",
    "\n",
    "# Save JSON\n",
    "prediction_json = df.head(20)[[\"Block\", \"Hybrid_Risk_Prediction\", \"Hybrid_Risk_Probability\"]].to_dict(orient=\"records\")\n",
    "\n",
    "with open(os.path.join(base_path, \"hybrid_predictions.json\"), \"w\") as f:\n",
    "    json.dump(prediction_json, f, indent=4)\n",
    "\n",
    "# Save YAML\n",
    "config = {\n",
    "    \"model\": \"Hybrid_AIS_CSA_RandomForest\",\n",
    "    \"accuracy\": float(hybrid_accuracy),\n",
    "    \"best_n_estimators\": int(best_params[0]),\n",
    "    \"best_max_depth\": int(best_params[1]),\n",
    "    \"feature_weights\": best_weights.tolist()\n",
    "}\n",
    "\n",
    "with open(os.path.join(base_path, \"hybrid_config.yaml\"), \"w\") as file:\n",
    "    yaml.dump(config, file)\n",
    "\n",
    "# ====================================================\n",
    "# PLOTS\n",
    "# ====================================================\n",
    "\n",
    "cm = confusion_matrix(y_test, hybrid_preds)\n",
    "\n",
    "plt.figure()\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\")\n",
    "plt.title(\"Hybrid Confusion Matrix\")\n",
    "plt.savefig(os.path.join(base_path, \"hybrid_confusion_matrix.png\"))\n",
    "plt.close()\n",
    "\n",
    "plt.figure()\n",
    "plt.bar([\"Hybrid AIS+CSA\"], [hybrid_accuracy])\n",
    "plt.title(\"Hybrid Model Accuracy\")\n",
    "plt.savefig(os.path.join(base_path, \"hybrid_accuracy_graph.png\"))\n",
    "plt.close()\n",
    "\n",
    "print(\"\\n✅ HYBRID AIS + CSA MODEL EXECUTED SUCCESSFULLY\")\n",
    "print(\"Hybrid Accuracy:\", hybrid_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83efdc78-9936-4225-a08c-aa12ae58c8ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
